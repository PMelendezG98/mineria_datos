{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducci√≥n a Python para Miner√≠a de Datos\n",
    "\n",
    "Este notebook cubre los fundamentos de Python necesarios para el curso de Miner√≠a de Datos. Est√° dise√±ado como una referencia completa que podr√°s consultar durante todo el semestre.\n",
    "\n",
    "## Contenido\n",
    "\n",
    "1. **Fundamentos de Python**: Tipos de datos, estructuras, control de flujo y funciones\n",
    "2. **NumPy**: Computaci√≥n num√©rica eficiente con arrays\n",
    "3. **Pandas**: Manipulaci√≥n y an√°lisis de datos estructurados\n",
    "4. **Visualizaci√≥n**: Creaci√≥n de gr√°ficos con Matplotlib y Seaborn\n",
    "5. **Caso Integrador**: An√°lisis de datos reales con Online Retail Dataset\n",
    "\n",
    "**Nota importante**: Este notebook cubre **exclusivamente** herramientas de manipulaci√≥n y visualizaci√≥n de datos. Los algoritmos de Machine Learning se cubrir√°n en notebooks posteriores del curso.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuraci√≥n del Entorno\n",
    "\n",
    "Primero importamos todas las librer√≠as que usaremos en este notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as para manipulaci√≥n de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Librer√≠as para visualizaci√≥n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas correctamente\")\n",
    "print(f\"  - NumPy versi√≥n: {np.__version__}\")\n",
    "print(f\"  - Pandas versi√≥n: {pd.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de visualizaci√≥n\n",
    "sns.set_style('whitegrid')  # Estilo de los gr√°ficos\n",
    "plt.rcParams['figure.figsize'] = (10, 6)  # Tama√±o por defecto de las figuras\n",
    "plt.rcParams['font.size'] = 10  # Tama√±o de fuente\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úì Configuraci√≥n visual establecida\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Fundamentos de Python\n",
    "\n",
    "**Objetivos de aprendizaje:**\n",
    "- Comprender los tipos de datos b√°sicos en Python\n",
    "- Dominar las estructuras de datos fundamentales (listas, diccionarios, tuplas)\n",
    "- Utilizar estructuras de control de flujo\n",
    "- Definir funciones con type hints\n",
    "\n",
    "**Conceptos clave**: tipos de datos, listas, diccionarios, iteraci√≥n, funciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tipos de Datos B√°sicos\n",
    "\n",
    "Python tiene varios tipos de datos b√°sicos que usaremos constantemente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enteros (int)\n",
    "numero_clientes = 1500\n",
    "print(f\"N√∫mero de clientes: {numero_clientes} (tipo: {type(numero_clientes).__name__})\")\n",
    "\n",
    "# Flotantes (float)\n",
    "precio_producto = 299.99\n",
    "print(f\"Precio del producto: ${precio_producto:.2f} (tipo: {type(precio_producto).__name__})\")\n",
    "\n",
    "# Cadenas de texto (str)\n",
    "nombre_producto = \"Laptop HP\"\n",
    "print(f\"Producto: {nombre_producto} (tipo: {type(nombre_producto).__name__})\")\n",
    "\n",
    "# Booleanos (bool)\n",
    "producto_disponible = True\n",
    "print(f\"¬øDisponible?: {producto_disponible} (tipo: {type(producto_disponible).__name__})\")\n",
    "\n",
    "# Operaciones aritm√©ticas b√°sicas\n",
    "ingreso_total = numero_clientes * precio_producto\n",
    "print(f\"\\nIngreso total estimado: ${ingreso_total:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operaciones con strings\n",
    "nombre = \"Juan\"\n",
    "apellido = \"P√©rez\"\n",
    "\n",
    "# Concatenaci√≥n\n",
    "nombre_completo = nombre + \" \" + apellido\n",
    "print(f\"Nombre completo: {nombre_completo}\")\n",
    "\n",
    "# Formateo con f-strings\n",
    "mensaje = f\"Bienvenido {nombre_completo}\"\n",
    "print(mensaje)\n",
    "\n",
    "# M√©todos √∫tiles de strings\n",
    "print(f\"\\nMay√∫sculas: {nombre_completo.upper()}\")\n",
    "print(f\"Min√∫sculas: {nombre_completo.lower()}\")\n",
    "print(f\"Longitud: {len(nombre_completo)} caracteres\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Estructuras de Datos\n",
    "\n",
    "Las estructuras de datos nos permiten organizar y almacenar informaci√≥n de manera eficiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LISTAS: Colecciones ordenadas y mutables\n",
    "regiones = ['Norte', 'Sur', 'Este', 'Oeste', 'Centro']\n",
    "print(f\"Regiones: {regiones}\")\n",
    "print(f\"N√∫mero de regiones: {len(regiones)}\")\n",
    "\n",
    "# Indexaci√≥n (empieza en 0)\n",
    "print(f\"\\nPrimera regi√≥n: {regiones[0]}\")\n",
    "print(f\"√öltima regi√≥n: {regiones[-1]}\")\n",
    "\n",
    "# Slicing (rebanado)\n",
    "print(f\"Primeras 3 regiones: {regiones[:3]}\")\n",
    "print(f\"√öltimas 2 regiones: {regiones[-2:]}\")\n",
    "\n",
    "# M√©todos √∫tiles\n",
    "regiones.append('Sureste')  # Agregar al final\n",
    "print(f\"\\nDespu√©s de agregar: {regiones}\")\n",
    "\n",
    "regiones.remove('Sureste')  # Eliminar elemento\n",
    "print(f\"Despu√©s de eliminar: {regiones}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICCIONARIOS: Colecciones de pares clave-valor\n",
    "producto = {\n",
    "    'nombre': 'Laptop',\n",
    "    'precio': 15000.00,\n",
    "    'stock': 45,\n",
    "    'categoria': 'Electr√≥nica',\n",
    "    'disponible': True\n",
    "}\n",
    "\n",
    "# Acceso a valores\n",
    "print(f\"Producto: {producto['nombre']}\")\n",
    "print(f\"Precio: ${producto['precio']:,.2f}\")\n",
    "print(f\"Stock disponible: {producto['stock']} unidades\")\n",
    "\n",
    "# M√©todos √∫tiles\n",
    "print(f\"\\nClaves: {list(producto.keys())}\")\n",
    "print(f\"Valores: {list(producto.values())}\")\n",
    "\n",
    "# Agregar nueva clave\n",
    "producto['marca'] = 'HP'\n",
    "print(f\"\\nProducto actualizado: {producto}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUPLAS: Colecciones ordenadas e inmutables\n",
    "coordenadas = (19.4326, -99.1332)  # Latitud, Longitud de CDMX\n",
    "print(f\"Coordenadas CDMX: {coordenadas}\")\n",
    "print(f\"Latitud: {coordenadas[0]}, Longitud: {coordenadas[1]}\")\n",
    "\n",
    "# Las tuplas son √∫tiles para retornar m√∫ltiples valores de una funci√≥n\n",
    "def obtener_estadisticas(numeros: list) -> tuple:\n",
    "    \"\"\"Retorna el m√≠nimo, m√°ximo y promedio de una lista de n√∫meros.\"\"\"\n",
    "    return min(numeros), max(numeros), sum(numeros) / len(numeros)\n",
    "\n",
    "ventas = [1200, 1500, 980, 2100, 1750]\n",
    "minimo, maximo, promedio = obtener_estadisticas(ventas)\n",
    "print(f\"\\nVentas - M√≠nimo: ${minimo:,.0f}, M√°ximo: ${maximo:,.0f}, Promedio: ${promedio:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Control de Flujo\n",
    "\n",
    "Las estructuras de control nos permiten tomar decisiones y repetir operaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condicionales: if / elif / else\n",
    "precio = 850.00\n",
    "\n",
    "if precio > 1000:\n",
    "    categoria_precio = \"Alto\"\n",
    "    descuento = 0.15\n",
    "elif precio > 500:\n",
    "    categoria_precio = \"Medio\"\n",
    "    descuento = 0.10\n",
    "else:\n",
    "    categoria_precio = \"Bajo\"\n",
    "    descuento = 0.05\n",
    "\n",
    "precio_final = precio * (1 - descuento)\n",
    "print(f\"Precio: ${precio:.2f}\")\n",
    "print(f\"Categor√≠a: {categoria_precio}\")\n",
    "print(f\"Descuento: {descuento * 100:.0f}%\")\n",
    "print(f\"Precio final: ${precio_final:.2f}\")\n",
    "\n",
    "# Operadores l√≥gicos\n",
    "stock_disponible = 10\n",
    "pedido_urgente = True\n",
    "\n",
    "if stock_disponible > 0 and pedido_urgente:\n",
    "    print(\"\\n‚úì Procesar pedido urgente\")\n",
    "elif stock_disponible == 0:\n",
    "    print(\"\\n‚úó Sin stock disponible\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucles FOR con range()\n",
    "print(\"Pron√≥stico de ventas para los pr√≥ximos 5 meses:\")\n",
    "venta_base = 10000\n",
    "\n",
    "for mes in range(1, 6):\n",
    "    crecimiento = 1.05 ** mes  # Crecimiento del 5% mensual compuesto\n",
    "    venta_proyectada = venta_base * crecimiento\n",
    "    print(f\"  Mes {mes}: ${venta_proyectada:,.2f}\")\n",
    "\n",
    "# Bucles FOR con enumerate() - muy √∫til cuando necesitas el √≠ndice\n",
    "print(\"\\nProductos m√°s vendidos:\")\n",
    "productos_top = ['Laptop', 'Mouse', 'Teclado', 'Monitor', 'Aud√≠fonos']\n",
    "\n",
    "for posicion, producto in enumerate(productos_top, start=1):\n",
    "    print(f\"  {posicion}. {producto}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehensions (estilo pyth√≥nico)\n",
    "precios = [100, 250, 380, 520, 890]\n",
    "\n",
    "# M√©todo tradicional\n",
    "precios_con_iva_tradicional = []\n",
    "for precio in precios:\n",
    "    precios_con_iva_tradicional.append(precio * 1.16)\n",
    "\n",
    "# List comprehension (m√°s pyth√≥nico y eficiente)\n",
    "precios_con_iva = [precio * 1.16 for precio in precios]\n",
    "print(f\"Precios con IVA: {[f'${p:.2f}' for p in precios_con_iva]}\")\n",
    "\n",
    "# Con filtrado\n",
    "precios_premium = [precio for precio in precios if precio > 300]\n",
    "print(f\"\\nProductos premium (precio > $300): {precios_premium}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Funciones con Type Hints\n",
    "\n",
    "Las funciones nos permiten encapsular l√≥gica reutilizable. Los type hints hacen el c√≥digo m√°s legible y mantenible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_descuento(precio: float, porcentaje_descuento: float) -> float:\n",
    "    \"\"\"\n",
    "    Calcula el precio final despu√©s de aplicar un descuento.\n",
    "    \n",
    "    Args:\n",
    "        precio: Precio original del producto\n",
    "        porcentaje_descuento: Descuento a aplicar (entre 0 y 1)\n",
    "        \n",
    "    Returns:\n",
    "        Precio final despu√©s del descuento\n",
    "        \n",
    "    Ejemplo:\n",
    "        >>> calcular_descuento(1000, 0.15)\n",
    "        850.0\n",
    "    \"\"\"\n",
    "    precio_final = precio * (1 - porcentaje_descuento)\n",
    "    return precio_final\n",
    "\n",
    "\n",
    "# Uso de la funci√≥n\n",
    "precio_original = 1500.00\n",
    "descuento = 0.20\n",
    "precio_con_descuento = calcular_descuento(precio_original, descuento)\n",
    "\n",
    "print(f\"Precio original: ${precio_original:,.2f}\")\n",
    "print(f\"Descuento: {descuento * 100:.0f}%\")\n",
    "print(f\"Precio final: ${precio_con_descuento:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_cliente(valor_compras: float, num_transacciones: int) -> str:\n",
    "    \"\"\"\n",
    "    Categoriza un cliente basado en su valor de compras y frecuencia.\n",
    "    \n",
    "    Args:\n",
    "        valor_compras: Valor total de compras del cliente\n",
    "        num_transacciones: N√∫mero de transacciones realizadas\n",
    "        \n",
    "    Returns:\n",
    "        Categor√≠a del cliente: 'Premium', 'Regular' o 'B√°sico'\n",
    "    \"\"\"\n",
    "    if valor_compras > 10000 and num_transacciones > 10:\n",
    "        return 'Premium'\n",
    "    elif valor_compras > 5000 or num_transacciones > 5:\n",
    "        return 'Regular'\n",
    "    else:\n",
    "        return 'B√°sico'\n",
    "\n",
    "\n",
    "# Ejemplos de categorizaci√≥n\n",
    "clientes = [\n",
    "    ('Cliente A', 15000, 15),\n",
    "    ('Cliente B', 6000, 8),\n",
    "    ('Cliente C', 2000, 3)\n",
    "]\n",
    "\n",
    "print(\"Categorizaci√≥n de clientes:\")\n",
    "for nombre, valor, transacciones in clientes:\n",
    "    categoria = categorizar_cliente(valor, transacciones)\n",
    "    ticket_promedio = valor / transacciones\n",
    "    print(f\"  {nombre}: {categoria} (${valor:,.0f} en {transacciones} compras, ticket: ${ticket_promedio:,.0f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. NumPy - Computaci√≥n Num√©rica\n",
    "\n",
    "**Objetivos de aprendizaje:**\n",
    "- Comprender las ventajas de NumPy sobre las listas de Python\n",
    "- Crear y manipular arrays multidimensionales\n",
    "- Realizar operaciones vectorizadas eficientes\n",
    "- Generar datos sint√©ticos para an√°lisis\n",
    "\n",
    "**Conceptos clave**: arrays, vectorizaci√≥n, broadcasting, indexaci√≥n, agregaciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Introducci√≥n a Arrays\n",
    "\n",
    "### ¬øPor qu√© NumPy?\n",
    "\n",
    "NumPy (Numerical Python) es la librer√≠a fundamental para computaci√≥n cient√≠fica en Python. Sus principales ventajas:\n",
    "\n",
    "1. **Velocidad**: Los arrays de NumPy son 10-100x m√°s r√°pidos que las listas de Python\n",
    "2. **Memoria**: Usan menos memoria que las listas equivalentes\n",
    "3. **Operaciones vectorizadas**: Permiten operaciones matem√°ticas sobre arrays completos sin bucles expl√≠citos\n",
    "4. **Broadcasting**: Operaciones entre arrays de diferentes formas\n",
    "\n",
    "üí° **Conexi√≥n con el curso**: NumPy es la base sobre la que se construye Pandas, y todas las operaciones num√©ricas en an√°lisis de datos lo utilizan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creaci√≥n de arrays desde listas\n",
    "ventas_semana = np.array([1200, 1500, 1100, 1800, 2100, 900, 1300])\n",
    "print(f\"Ventas de la semana: {ventas_semana}\")\n",
    "print(f\"Tipo: {type(ventas_semana)}\")\n",
    "\n",
    "# Atributos importantes de un array\n",
    "print(f\"\\nAtributos del array:\")\n",
    "print(f\"  - Shape (forma): {ventas_semana.shape}\")\n",
    "print(f\"  - Dtype (tipo de datos): {ventas_semana.dtype}\")\n",
    "print(f\"  - Ndim (n√∫mero de dimensiones): {ventas_semana.ndim}\")\n",
    "print(f\"  - Size (n√∫mero total de elementos): {ventas_semana.size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferentes formas de crear arrays\n",
    "\n",
    "# Array de ceros\n",
    "inventario = np.zeros(5)\n",
    "print(f\"Inventario inicial (ceros): {inventario}\")\n",
    "\n",
    "# Array de unos\n",
    "productos_activos = np.ones(5)\n",
    "print(f\"Productos activos (unos): {productos_activos}\")\n",
    "\n",
    "# Array con rango de valores\n",
    "dias_mes = np.arange(1, 31)  # Del 1 al 30\n",
    "print(f\"\\nD√≠as del mes: {dias_mes}\")\n",
    "\n",
    "# Array con valores espaciados uniformemente\n",
    "percentiles = np.linspace(0, 100, 11)  # 11 puntos entre 0 y 100\n",
    "print(f\"\\nPercentiles: {percentiles}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays multidimensionales (matrices)\n",
    "# Ventas por regi√≥n (filas) y producto (columnas)\n",
    "ventas_matriz = np.array([\n",
    "    [1200, 1500, 980],   # Norte\n",
    "    [1100, 1300, 1050],  # Sur\n",
    "    [1400, 1250, 1100],  # Este\n",
    "    [1350, 1450, 1200]   # Oeste\n",
    "])\n",
    "\n",
    "print(\"Matriz de ventas por regi√≥n y producto:\")\n",
    "print(ventas_matriz)\n",
    "print(f\"\\nShape: {ventas_matriz.shape} (4 regiones √ó 3 productos)\")\n",
    "print(f\"N√∫mero de dimensiones: {ventas_matriz.ndim}\")\n",
    "print(f\"Total de elementos: {ventas_matriz.size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Generaci√≥n de Datos Sint√©ticos\n",
    "\n",
    "NumPy nos permite generar datos aleatorios que siguen diferentes distribuciones estad√≠sticas. Esto es √∫til para:\n",
    "- Crear datos de prueba\n",
    "- Simular escenarios de negocio\n",
    "- Probar algoritmos antes de usar datos reales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "# N√∫meros aleatorios uniformes (todos los valores tienen la misma probabilidad)\n",
    "precios_aleatorios = np.random.uniform(low=50, high=1500, size=10)\n",
    "print(\"Precios aleatorios (distribuci√≥n uniforme entre $50 y $1500):\")\n",
    "print([f\"${p:.2f}\" for p in precios_aleatorios])\n",
    "\n",
    "# N√∫meros enteros aleatorios\n",
    "cantidades = np.random.randint(low=1, high=10, size=10)\n",
    "print(f\"\\nCantidades vendidas (enteros entre 1 y 10): {cantidades}\")\n",
    "\n",
    "# N√∫meros aleatorios con distribuci√≥n normal (campana de Gauss)\n",
    "# √ötil para simular medidas naturales: alturas, tiempos, errores, etc.\n",
    "tiempos_entrega = np.random.normal(loc=3.0, scale=0.5, size=100)  # Media=3 d√≠as, desv.std=0.5\n",
    "print(f\"\\nTiempos de entrega (distribuci√≥n normal):\")\n",
    "print(f\"  Media: {tiempos_entrega.mean():.2f} d√≠as\")\n",
    "print(f\"  Desviaci√≥n est√°ndar: {tiempos_entrega.std():.2f} d√≠as\")\n",
    "print(f\"  Rango: {tiempos_entrega.min():.2f} - {tiempos_entrega.max():.2f} d√≠as\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestreo de categor√≠as con np.random.choice()\n",
    "regiones = np.array(['Norte', 'Sur', 'Este', 'Oeste', 'Centro'])\n",
    "productos = np.array(['Laptop', 'Mouse', 'Teclado', 'Monitor', 'Aud√≠fonos', 'Webcam'])\n",
    "\n",
    "# Generar 20 ventas aleatorias\n",
    "n_ventas = 20\n",
    "regiones_ventas = np.random.choice(regiones, size=n_ventas)\n",
    "productos_ventas = np.random.choice(productos, size=n_ventas)\n",
    "\n",
    "print(\"Primeras 10 transacciones simuladas:\")\n",
    "for i in range(10):\n",
    "    print(f\"  Venta {i+1}: {productos_ventas[i]} en regi√≥n {regiones_ventas[i]}\")\n",
    "\n",
    "# Tambi√©n podemos especificar probabilidades\n",
    "segmentos_cliente = np.random.choice(\n",
    "    ['Premium', 'Regular', 'B√°sico'],\n",
    "    size=100,\n",
    "    p=[0.2, 0.5, 0.3]  # 20% Premium, 50% Regular, 30% B√°sico\n",
    ")\n",
    "print(f\"\\nDistribuci√≥n de segmentos (100 clientes):\")\n",
    "print(f\"  Premium: {(segmentos_cliente == 'Premium').sum()}\")\n",
    "print(f\"  Regular: {(segmentos_cliente == 'Regular').sum()}\")\n",
    "print(f\"  B√°sico: {(segmentos_cliente == 'B√°sico').sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Operaciones con Arrays\n",
    "\n",
    "Una de las mayores ventajas de NumPy es la **vectorizaci√≥n**: podemos aplicar operaciones a arrays completos sin escribir bucles expl√≠citos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operaciones vectorizadas b√°sicas\n",
    "precios = np.array([100, 250, 380, 520, 890])\n",
    "print(f\"Precios originales: {precios}\")\n",
    "\n",
    "# Aplicar IVA (16%) a todos los precios a la vez\n",
    "precios_con_iva = precios * 1.16\n",
    "print(f\"Precios con IVA: {[f'${p:.2f}' for p in precios_con_iva]}\")\n",
    "\n",
    "# Aplicar descuento del 20%\n",
    "precios_descuento = precios * 0.80\n",
    "print(f\"Precios con descuento: {[f'${p:.2f}' for p in precios_descuento]}\")\n",
    "\n",
    "# Operaciones entre arrays\n",
    "cantidades = np.array([5, 3, 2, 4, 1])\n",
    "ingresos = precios * cantidades\n",
    "print(f\"\\nIngresos por producto: {[f'${i:,.0f}' for i in ingresos]}\")\n",
    "print(f\"Ingreso total: ${ingresos.sum():,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting: operaciones entre arrays de diferentes formas\n",
    "# Ejemplo: calcular precio final para diferentes descuentos en m√∫ltiples productos\n",
    "\n",
    "precios = np.array([[100], [250], [380]])  # 3 productos (columna)\n",
    "descuentos = np.array([0.10, 0.15, 0.20, 0.25])  # 4 niveles de descuento (fila)\n",
    "\n",
    "# NumPy autom√°ticamente expande ambos arrays para hacer la operaci√≥n\n",
    "precios_finales = precios * (1 - descuentos)\n",
    "\n",
    "print(\"Matriz de precios finales (productos √ó descuentos):\")\n",
    "print(precios_finales)\n",
    "print(f\"\\nShape: {precios_finales.shape} (3 productos √ó 4 niveles de descuento)\")\n",
    "\n",
    "print(\"\\nInterpretaci√≥n:\")\n",
    "productos_nombres = ['Producto A ($100)', 'Producto B ($250)', 'Producto C ($380)']\n",
    "for i, nombre in enumerate(productos_nombres):\n",
    "    print(f\"{nombre}: {[f'${p:.0f}' for p in precios_finales[i]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores = np.array([4, 9, 16, 25, 36])\n",
    "print(f\"Valores: {valores}\")\n",
    "\n",
    "# Ra√≠z cuadrada\n",
    "raices = np.sqrt(valores)\n",
    "print(f\"Ra√≠ces cuadradas: {raices}\")\n",
    "\n",
    "# Logaritmo natural\n",
    "ventas = np.array([100, 1000, 10000, 100000])\n",
    "log_ventas = np.log10(ventas)  # Logaritmo base 10\n",
    "print(f\"\\nVentas: {ventas}\")\n",
    "print(f\"Log10 de ventas: {log_ventas}\")\n",
    "\n",
    "# Exponencial (crecimiento compuesto)\n",
    "tasas_crecimiento = np.array([0.05, 0.10, 0.15, 0.20])  # 5%, 10%, 15%, 20%\n",
    "periodos = 12  # meses\n",
    "multiplicadores = np.exp(tasas_crecimiento * periodos)\n",
    "print(f\"\\nMultiplicadores de crecimiento despu√©s de {periodos} meses:\")\n",
    "for tasa, mult in zip(tasas_crecimiento, multiplicadores):\n",
    "    print(f\"  Tasa {tasa*100:.0f}%: {mult:.2f}x\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregaciones: calcular estad√≠sticas sobre arrays\n",
    "ventas_mes = np.random.randint(low=5000, high=15000, size=30)  # 30 d√≠as\n",
    "\n",
    "print(f\"Ventas del mes (30 d√≠as):\")\n",
    "print(f\"  Total: ${ventas_mes.sum():,.2f}\")\n",
    "print(f\"  Promedio diario: ${ventas_mes.mean():,.2f}\")\n",
    "print(f\"  Mediana: ${np.median(ventas_mes):,.2f}\")\n",
    "print(f\"  Desviaci√≥n est√°ndar: ${ventas_mes.std():,.2f}\")\n",
    "print(f\"  M√≠nimo: ${ventas_mes.min():,.2f}\")\n",
    "print(f\"  M√°ximo: ${ventas_mes.max():,.2f}\")\n",
    "print(f\"  Rango (max - min): ${ventas_mes.max() - ventas_mes.min():,.2f}\")\n",
    "\n",
    "# Percentiles\n",
    "percentiles = np.percentile(ventas_mes, [25, 50, 75, 90, 95])\n",
    "print(f\"\\nPercentiles de ventas:\")\n",
    "for p, valor in zip([25, 50, 75, 90, 95], percentiles):\n",
    "    print(f\"  P{p}: ${valor:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Indexaci√≥n y Slicing\n",
    "\n",
    "La indexaci√≥n nos permite acceder y modificar elementos espec√≠ficos de un array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexaci√≥n b√°sica 1D\n",
    "ventas_semana = np.array([1200, 1500, 1100, 1800, 2100, 900, 1300])\n",
    "dias = ['Lun', 'Mar', 'Mi√©', 'Jue', 'Vie', 'S√°b', 'Dom']\n",
    "\n",
    "print(\"Ventas por d√≠a:\")\n",
    "for dia, venta in zip(dias, ventas_semana):\n",
    "    print(f\"  {dia}: ${venta:,.0f}\")\n",
    "\n",
    "print(f\"\\nVentas del lunes (√≠ndice 0): ${ventas_semana[0]:,}\")\n",
    "print(f\"Ventas del domingo (√≠ndice -1): ${ventas_semana[-1]:,}\")\n",
    "\n",
    "# Slicing (rebanado)\n",
    "ventas_lun_a_vie = ventas_semana[:5]  # Primeros 5 elementos\n",
    "ventas_fin_semana = ventas_semana[-2:]  # √öltimos 2 elementos\n",
    "\n",
    "print(f\"\\nVentas lun-vie: ${ventas_lun_a_vie.sum():,} (promedio: ${ventas_lun_a_vie.mean():,.0f})\")\n",
    "print(f\"Ventas fin de semana: ${ventas_fin_semana.sum():,} (promedio: ${ventas_fin_semana.mean():,.0f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexaci√≥n booleana (masking)\n",
    "ventas_semana = np.array([1200, 1500, 1100, 1800, 2100, 900, 1300])\n",
    "\n",
    "# Crear una m√°scara booleana\n",
    "ventas_altas = ventas_semana > 1400\n",
    "print(f\"M√°scara de ventas > $1400: {ventas_altas}\")\n",
    "\n",
    "# Usar la m√°scara para filtrar\n",
    "dias_buenos = ventas_semana[ventas_altas]\n",
    "print(f\"D√≠as con ventas > $1400: {dias_buenos} (${dias_buenos.sum():,} total)\")\n",
    "\n",
    "# Filtrado directo\n",
    "ventas_bajas = ventas_semana[ventas_semana < 1200]\n",
    "print(f\"D√≠as con ventas < $1200: {ventas_bajas}\")\n",
    "\n",
    "# M√∫ltiples condiciones con & (and) y | (or)\n",
    "ventas_medias = ventas_semana[(ventas_semana >= 1200) & (ventas_semana <= 1500)]\n",
    "print(f\"D√≠as con ventas entre $1200 y $1500: {ventas_medias}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexaci√≥n en arrays 2D (matrices)\n",
    "# Ventas por regi√≥n (filas) y producto (columnas)\n",
    "ventas_matriz = np.array([\n",
    "    [1200, 1500, 980],   # Norte\n",
    "    [1100, 1300, 1050],  # Sur\n",
    "    [1400, 1250, 1100],  # Este\n",
    "    [1350, 1450, 1200]   # Oeste\n",
    "])\n",
    "\n",
    "regiones_nombres = ['Norte', 'Sur', 'Este', 'Oeste']\n",
    "productos_nombres = ['Producto A', 'Producto B', 'Producto C']\n",
    "\n",
    "# Acceder a elemento espec√≠fico: fila 0, columna 1\n",
    "print(f\"Ventas de Producto B en Norte: ${ventas_matriz[0, 1]:,}\")\n",
    "\n",
    "# Acceder a fila completa (todas las ventas de una regi√≥n)\n",
    "ventas_norte = ventas_matriz[0, :]  # o simplemente ventas_matriz[0]\n",
    "print(f\"\\nVentas en Norte: {ventas_norte} (Total: ${ventas_norte.sum():,})\")\n",
    "\n",
    "# Acceder a columna completa (todas las ventas de un producto)\n",
    "ventas_producto_a = ventas_matriz[:, 0]\n",
    "print(f\"Ventas de Producto A en todas las regiones: {ventas_producto_a}\")\n",
    "\n",
    "# Agregaciones por filas y columnas\n",
    "print(f\"\\nTotal por regi√≥n:\")\n",
    "totales_region = ventas_matriz.sum(axis=1)  # Sumar a lo largo de las columnas\n",
    "for region, total in zip(regiones_nombres, totales_region):\n",
    "    print(f\"  {region}: ${total:,}\")\n",
    "\n",
    "print(f\"\\nTotal por producto:\")\n",
    "totales_producto = ventas_matriz.sum(axis=0)  # Sumar a lo largo de las filas\n",
    "for producto, total in zip(productos_nombres, totales_producto):\n",
    "    print(f\"  {producto}: ${total:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Manipulaci√≥n de Dimensiones\n",
    "\n",
    "A veces necesitamos cambiar la forma de nuestros arrays para realizar ciertas operaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape: cambiar la forma del array sin modificar los datos\n",
    "ventas_12_meses = np.arange(1, 13) * 1000  # [1000, 2000, ..., 12000]\n",
    "print(f\"Ventas originales (12 meses): {ventas_12_meses}\")\n",
    "print(f\"Shape: {ventas_12_meses.shape}\")\n",
    "\n",
    "# Reorganizar como 4 trimestres √ó 3 meses\n",
    "ventas_por_trimestre = ventas_12_meses.reshape(4, 3)\n",
    "print(f\"\\nVentas por trimestre (4 √ó 3):\")\n",
    "print(ventas_por_trimestre)\n",
    "\n",
    "# Calcular totales por trimestre\n",
    "totales_trimestre = ventas_por_trimestre.sum(axis=1)\n",
    "print(f\"\\nTotales por trimestre: {[f'${t:,}' for t in totales_trimestre]}\")\n",
    "\n",
    "# Volver a forma original\n",
    "ventas_flat = ventas_por_trimestre.flatten()  # o .reshape(-1)\n",
    "print(f\"\\nDe vuelta a forma 1D: {ventas_flat}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose (transponer): intercambiar filas y columnas\n",
    "ventas_regiones_productos = np.array([\n",
    "    [1200, 1500, 980],   # Norte\n",
    "    [1100, 1300, 1050],  # Sur\n",
    "    [1400, 1250, 1100]   # Este\n",
    "])\n",
    "\n",
    "print(\"Ventas originales (regiones √ó productos):\")\n",
    "print(ventas_regiones_productos)\n",
    "print(f\"Shape: {ventas_regiones_productos.shape}\")\n",
    "\n",
    "# Transponer\n",
    "ventas_productos_regiones = ventas_regiones_productos.T\n",
    "print(\"\\nVentas transpuestas (productos √ó regiones):\")\n",
    "print(ventas_productos_regiones)\n",
    "print(f\"Shape: {ventas_productos_regiones.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenaci√≥n de arrays\n",
    "ventas_q1 = np.array([10000, 12000, 11000])  # Ene, Feb, Mar\n",
    "ventas_q2 = np.array([13000, 14000, 15000])  # Abr, May, Jun\n",
    "\n",
    "# Concatenar horizontalmente\n",
    "ventas_semestre = np.concatenate([ventas_q1, ventas_q2])\n",
    "print(f\"Ventas primer semestre: {ventas_semestre}\")\n",
    "\n",
    "# Apilar verticalmente (crear matriz)\n",
    "ventas_comparacion = np.vstack([ventas_q1, ventas_q2])\n",
    "print(f\"\\nComparaci√≥n por trimestre:\")\n",
    "print(ventas_comparacion)\n",
    "print(f\"Diferencia Q2-Q1: {ventas_comparacion[1] - ventas_comparacion[0]}\")\n",
    "\n",
    "# Apilar horizontalmente\n",
    "norte = np.array([[1200], [1500], [1100]])\n",
    "sur = np.array([[1100], [1300], [1050]])\n",
    "ventas_combinadas = np.hstack([norte, sur])\n",
    "print(f\"\\nVentas Norte y Sur por mes:\")\n",
    "print(ventas_combinadas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Pandas - Manipulaci√≥n de Datos\n",
    "\n",
    "**Objetivos de aprendizaje:**\n",
    "- Comprender la estructura de Series y DataFrames\n",
    "- Dominar t√©cnicas de selecci√≥n, filtrado e indexaci√≥n\n",
    "- Realizar agregaciones y transformaciones de datos\n",
    "- Combinar datasets con joins y merges\n",
    "- Trabajar con strings, fechas y datos faltantes\n",
    "\n",
    "**Conceptos clave**: Series, DataFrame, indexaci√≥n, groupby, joins, limpieza de datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creaci√≥n de Datos Sint√©ticos\n",
    "\n",
    "Primero crearemos datasets sint√©ticos que usaremos a lo largo de esta secci√≥n:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos datos sint√©ticos de ventas (1000 transacciones)\n",
    "np.random.seed(42)\n",
    "\n",
    "n_transacciones = 1000\n",
    "\n",
    "ventas_df = pd.DataFrame({\n",
    "    'fecha': pd.date_range('2023-01-01', periods=n_transacciones, freq='h'),\n",
    "    'producto': np.random.choice(['Laptop', 'Mouse', 'Teclado', 'Monitor', 'Aud√≠fonos', 'Webcam'], n_transacciones),\n",
    "    'categoria': np.random.choice(['Electr√≥nica', 'Accesorios', 'Computadoras'], n_transacciones, p=[0.3, 0.4, 0.3]),\n",
    "    'cantidad': np.random.randint(1, 10, n_transacciones),\n",
    "    'precio_unitario': np.random.uniform(50, 1500, n_transacciones).round(2),\n",
    "    'cliente_id': np.random.randint(1, 201, n_transacciones),\n",
    "    'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste', 'Centro'], n_transacciones)\n",
    "})\n",
    "\n",
    "# Crear columna calculada\n",
    "ventas_df['ingreso_total'] = ventas_df['cantidad'] * ventas_df['precio_unitario']\n",
    "\n",
    "print(f\"‚úì Dataset de ventas creado: {ventas_df.shape[0]} transacciones\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "print(ventas_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset de clientes (para joins posteriores)\n",
    "n_clientes = 200\n",
    "\n",
    "clientes_df = pd.DataFrame({\n",
    "    'cliente_id': range(1, n_clientes + 1),\n",
    "    'nombre': [f'Cliente_{i}' for i in range(1, n_clientes + 1)],\n",
    "    'segmento': np.random.choice(['Premium', 'Regular', 'B√°sico'], n_clientes, p=[0.2, 0.5, 0.3]),\n",
    "    'fecha_registro': pd.date_range('2020-01-01', periods=n_clientes, freq='D')\n",
    "})\n",
    "\n",
    "print(f\"‚úì Dataset de clientes creado: {clientes_df.shape[0]} clientes\")\n",
    "print(f\"\\nPrimeras 5 filas:\")\n",
    "print(clientes_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Series\n",
    "\n",
    "Una Series es un array unidimensional etiquetado, similar a una columna de Excel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear Series desde una lista\n",
    "precios = pd.Series([100, 250, 380, 520, 890], name='precio')\n",
    "print(\"Series de precios:\")\n",
    "print(precios)\n",
    "\n",
    "# Series desde un diccionario (con √≠ndices personalizados)\n",
    "ventas_region = pd.Series({\n",
    "    'Norte': 45000,\n",
    "    'Sur': 38000,\n",
    "    'Este': 52000,\n",
    "    'Oeste': 41000,\n",
    "    'Centro': 48000\n",
    "}, name='ventas')\n",
    "\n",
    "print(\"\\nSeries de ventas por regi√≥n:\")\n",
    "print(ventas_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexaci√≥n en Series\n",
    "print(f\"Ventas en el Norte: ${ventas_region['Norte']:,}\")\n",
    "print(f\"Ventas en el Sur: ${ventas_region['Sur']:,}\")\n",
    "\n",
    "# Indexaci√≥n por posici√≥n\n",
    "print(f\"\\nPrimera regi√≥n (posici√≥n 0): ${ventas_region.iloc[0]:,}\")\n",
    "print(f\"√öltimas 2 regiones: {ventas_region.iloc[-2:]}\")\n",
    "\n",
    "# Operaciones vectorizadas\n",
    "ventas_en_miles = ventas_region / 1000\n",
    "print(f\"\\nVentas en miles:\")\n",
    "print(ventas_en_miles.round(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√©todos √∫tiles de Series\n",
    "productos = pd.Series(['Laptop', 'Mouse', 'Laptop', 'Teclado', 'Mouse', 'Laptop', 'Monitor', 'Mouse'])\n",
    "\n",
    "print(\"Valores √∫nicos:\")\n",
    "print(productos.unique())\n",
    "\n",
    "print(f\"\\nN√∫mero de valores √∫nicos: {productos.nunique()}\")\n",
    "\n",
    "print(\"\\nConteo de frecuencias:\")\n",
    "print(productos.value_counts())\n",
    "\n",
    "# Estad√≠sticas descriptivas\n",
    "print(\"\\nEstad√≠sticas de ventas por regi√≥n:\")\n",
    "print(ventas_region.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 DataFrames - Creaci√≥n y Exploraci√≥n\n",
    "\n",
    "Un DataFrame es una tabla bidimensional con filas y columnas etiquetadas, similar a una hoja de Excel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya creamos ventas_df arriba, ahora explor√©moslo\n",
    "\n",
    "print(\"Informaci√≥n general del DataFrame:\")\n",
    "print(ventas_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributos importantes\n",
    "print(f\"Shape (forma): {ventas_df.shape} (filas √ó columnas)\")\n",
    "print(f\"\\nColumnas: {list(ventas_df.columns)}\")\n",
    "print(f\"\\nTipos de datos:\")\n",
    "print(ventas_df.dtypes)\n",
    "print(f\"\\n√çndice: {ventas_df.index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√©todos de inspecci√≥n\n",
    "print(\"Primeras 10 filas:\")\n",
    "print(ventas_df.head(10))\n",
    "\n",
    "print(\"\\n√öltimas 5 filas:\")\n",
    "print(ventas_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas descriptivas\n",
    "print(\"Estad√≠sticas descriptivas de columnas num√©ricas:\")\n",
    "print(ventas_df.describe().round(2))\n",
    "\n",
    "# Para todas las columnas (incluyendo categ√≥ricas)\n",
    "print(\"\\nDescripci√≥n de columnas categ√≥ricas:\")\n",
    "print(ventas_df[['producto', 'region']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecci√≥n de columnas\n",
    "# M√©todo 1: Notaci√≥n de corchetes\n",
    "print(\"Seleccionar una columna (devuelve Series):\")\n",
    "print(ventas_df['producto'].head())\n",
    "\n",
    "# Seleccionar m√∫ltiples columnas (devuelve DataFrame)\n",
    "print(\"\\nSeleccionar m√∫ltiples columnas:\")\n",
    "columnas_interes = ['fecha', 'producto', 'ingreso_total']\n",
    "print(ventas_df[columnas_interes].head())\n",
    "\n",
    "# M√©todo 2: Notaci√≥n de punto (solo para nombres sin espacios)\n",
    "print(f\"\\nUsando notaci√≥n de punto:\")\n",
    "print(f\"Precio promedio: ${ventas_df.precio_unitario.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Indexaci√≥n y Selecci√≥n\n",
    "\n",
    "Pandas ofrece m√∫ltiples formas de seleccionar datos. Las dos principales son `.loc[]` (por etiqueta) y `.iloc[]` (por posici√≥n).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .loc[] - Indexaci√≥n por etiqueta\n",
    "print(\"Seleccionar filas 0 a 4 con .loc:\")\n",
    "print(ventas_df.loc[0:4, ['producto', 'cantidad', 'ingreso_total']])\n",
    "\n",
    "# .iloc[] - Indexaci√≥n por posici√≥n\n",
    "print(\"\\nSeleccionar primeras 5 filas y primeras 3 columnas con .iloc:\")\n",
    "print(ventas_df.iloc[0:5, 0:3])\n",
    "\n",
    "# Seleccionar filas y columnas espec√≠ficas\n",
    "print(\"\\nSeleccionar filas [0, 5, 10] y columnas espec√≠ficas:\")\n",
    "print(ventas_df.loc[[0, 5, 10], ['producto', 'precio_unitario', 'cantidad']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecci√≥n booleana (filtrado condicional)\n",
    "# Filtrar ventas mayores a $5000\n",
    "ventas_altas = ventas_df[ventas_df['ingreso_total'] > 5000]\n",
    "print(f\"Transacciones con ingreso > $5000: {len(ventas_altas)}\")\n",
    "print(ventas_altas[['producto', 'cantidad', 'precio_unitario', 'ingreso_total']].head())\n",
    "\n",
    "# M√∫ltiples condiciones con & (and), | (or), ~ (not)\n",
    "ventas_laptops_norte = ventas_df[\n",
    "    (ventas_df['producto'] == 'Laptop') & \n",
    "    (ventas_df['region'] == 'Norte')\n",
    "]\n",
    "print(f\"\\nLaptops vendidas en el Norte: {len(ventas_laptops_norte)}\")\n",
    "print(f\"Ingreso total: ${ventas_laptops_norte['ingreso_total'].sum():,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√©todo .query() - sintaxis tipo SQL\n",
    "# Equivalente al filtrado anterior\n",
    "ventas_laptops_norte_query = ventas_df.query(\"producto == 'Laptop' and region == 'Norte'\")\n",
    "print(f\"Con .query(): {len(ventas_laptops_norte_query)} transacciones\")\n",
    "\n",
    "# Query m√°s compleja\n",
    "ventas_premium = ventas_df.query(\"ingreso_total > 3000 and (region == 'Norte' or region == 'Sur')\")\n",
    "print(f\"\\nVentas premium en Norte o Sur: {len(ventas_premium)}\")\n",
    "print(f\"Productos m√°s vendidos:\")\n",
    "print(ventas_premium['producto'].value_counts().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Manipulaci√≥n de Columnas\n",
    "\n",
    "Podemos crear nuevas columnas y transformar las existentes f√°cilmente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nuevas columnas a partir de c√°lculos\n",
    "ventas_df['ingreso_con_iva'] = ventas_df['ingreso_total'] * 1.16\n",
    "ventas_df['descuento_10pct'] = ventas_df['ingreso_total'] * 0.10\n",
    "ventas_df['precio_final'] = ventas_df['ingreso_total'] - ventas_df['descuento_10pct']\n",
    "\n",
    "print(\"Nuevas columnas creadas:\")\n",
    "print(ventas_df[['ingreso_total', 'ingreso_con_iva', 'descuento_10pct', 'precio_final']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizaci√≥n con .apply()\n",
    "def categorizar_venta(ingreso):\n",
    "    if ingreso > 5000:\n",
    "        return 'Alta'\n",
    "    elif ingreso > 2000:\n",
    "        return 'Media'\n",
    "    else:\n",
    "        return 'Baja'\n",
    "\n",
    "ventas_df['categoria_venta'] = ventas_df['ingreso_total'].apply(categorizar_venta)\n",
    "\n",
    "print(\"Distribuci√≥n de categor√≠as de venta:\")\n",
    "print(ventas_df['categoria_venta'].value_counts())\n",
    "print(f\"\\nEjemplo de categorizaci√≥n:\")\n",
    "print(ventas_df[['ingreso_total', 'categoria_venta']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar valores con .map() y .replace()\n",
    "# Renombrar regiones\n",
    "mapeo_regiones = {\n",
    "    'Norte': 'N',\n",
    "    'Sur': 'S',\n",
    "    'Este': 'E',\n",
    "    'Oeste': 'O',\n",
    "    'Centro': 'C'\n",
    "}\n",
    "ventas_df['region_codigo'] = ventas_df['region'].map(mapeo_regiones)\n",
    "\n",
    "print(\"Mapeo de regiones a c√≥digos:\")\n",
    "print(ventas_df[['region', 'region_codigo']].head())\n",
    "\n",
    "# Reemplazar valores espec√≠ficos\n",
    "print(f\"\\nConteo antes del reemplazo:\")\n",
    "print(ventas_df['categoria'].value_counts())\n",
    "\n",
    "# Eliminar columnas temporales\n",
    "ventas_df = ventas_df.drop(['ingreso_con_iva', 'descuento_10pct', 'precio_final', 'region_codigo'], axis=1)\n",
    "print(f\"\\nColumnas actuales: {list(ventas_df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Agregaciones y Estad√≠sticas\n",
    "\n",
    "Las agregaciones nos permiten resumir grandes cantidades de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de agregaci√≥n b√°sicas\n",
    "print(\"Estad√≠sticas de ingresos:\")\n",
    "print(f\"  Total: ${ventas_df['ingreso_total'].sum():,.2f}\")\n",
    "print(f\"  Promedio: ${ventas_df['ingreso_total'].mean():,.2f}\")\n",
    "print(f\"  Mediana: ${ventas_df['ingreso_total'].median():,.2f}\")\n",
    "print(f\"  M√≠nimo: ${ventas_df['ingreso_total'].min():,.2f}\")\n",
    "print(f\"  M√°ximo: ${ventas_df['ingreso_total'].max():,.2f}\")\n",
    "print(f\"  Desv. Est√°ndar: ${ventas_df['ingreso_total'].std():,.2f}\")\n",
    "\n",
    "# M√∫ltiples agregaciones con .agg()\n",
    "estadisticas = ventas_df['ingreso_total'].agg(['sum', 'mean', 'median', 'min', 'max', 'std'])\n",
    "print(\"\\nEstad√≠sticas con .agg():\")\n",
    "print(estadisticas.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregaciones en m√∫ltiples columnas\n",
    "resumen = ventas_df[['cantidad', 'precio_unitario', 'ingreso_total']].agg({\n",
    "    'cantidad': ['sum', 'mean'],\n",
    "    'precio_unitario': ['min', 'max', 'mean'],\n",
    "    'ingreso_total': ['sum', 'mean', 'median']\n",
    "})\n",
    "\n",
    "print(\"Resumen de m√∫ltiples columnas:\")\n",
    "print(resumen.round(2))\n",
    "\n",
    "# Percentiles con .quantile()\n",
    "percentiles = ventas_df['ingreso_total'].quantile([0.25, 0.50, 0.75, 0.90, 0.95])\n",
    "print(\"\\nPercentiles de ingresos:\")\n",
    "for q, valor in percentiles.items():\n",
    "    print(f\"  P{int(q*100)}: ${valor:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 GroupBy - El Poder de la Agregaci√≥n\n",
    "\n",
    "El m√©todo `.groupby()` implementa el patr√≥n **split-apply-combine**, una de las operaciones m√°s poderosas de Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupaci√≥n simple: ventas totales por regi√≥n\n",
    "ventas_por_region = ventas_df.groupby('region')['ingreso_total'].sum().sort_values(ascending=False)\n",
    "print(\"Ventas totales por regi√≥n:\")\n",
    "print(ventas_por_region.apply(lambda x: f\"${x:,.2f}\"))\n",
    "\n",
    "# Agrupaci√≥n con m√∫ltiples agregaciones\n",
    "resumen_region = ventas_df.groupby('region').agg({\n",
    "    'ingreso_total': ['sum', 'mean', 'count'],\n",
    "    'cantidad': 'sum',\n",
    "    'cliente_id': 'nunique'  # N√∫mero de clientes √∫nicos\n",
    "})\n",
    "print(\"\\nResumen por regi√≥n:\")\n",
    "print(resumen_region.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupaci√≥n por m√∫ltiples columnas\n",
    "ventas_region_producto = ventas_df.groupby(['region', 'producto'])['ingreso_total'].sum()\n",
    "print(\"Ventas por regi√≥n y producto (primeras 15):\")\n",
    "print(ventas_region_producto.sort_values(ascending=False).head(15))\n",
    "\n",
    "# Convertir a tabla pivote\n",
    "pivot_ventas = ventas_region_producto.unstack(fill_value=0)\n",
    "print(\"\\nFormato de tabla pivote:\")\n",
    "print(pivot_ventas.round(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform: agregar columna con estad√≠stica del grupo\n",
    "ventas_df['ingreso_promedio_region'] = ventas_df.groupby('region')['ingreso_total'].transform('mean')\n",
    "\n",
    "print(\"Comparaci√≥n de ingreso vs promedio regional:\")\n",
    "print(ventas_df[['region', 'producto', 'ingreso_total', 'ingreso_promedio_region']].head(10).round(2))\n",
    "\n",
    "# Calcular desviaci√≥n respecto al promedio regional\n",
    "ventas_df['desviacion_region'] = ventas_df['ingreso_total'] - ventas_df['ingreso_promedio_region']\n",
    "print(f\"\\nTransacciones por encima del promedio regional: {(ventas_df['desviacion_region'] > 0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrado de grupos con .filter()\n",
    "# Mantener solo regiones con m√°s de 180 transacciones\n",
    "regiones_activas = ventas_df.groupby('region').filter(lambda x: len(x) > 180)\n",
    "print(f\"Transacciones en regiones activas (>180 transacciones): {len(regiones_activas)}\")\n",
    "print(f\"Regiones incluidas: {regiones_activas['region'].unique()}\")\n",
    "\n",
    "# Top productos por regi√≥n\n",
    "top_producto_region = ventas_df.groupby('region').apply(\n",
    "    lambda x: x.groupby('producto')['ingreso_total'].sum().idxmax()\n",
    ")\n",
    "print(\"\\nProducto m√°s vendido por regi√≥n:\")\n",
    "print(top_producto_region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Operaciones con Strings (.str accessor)\n",
    "\n",
    "El accessor `.str` nos permite aplicar operaciones de strings a Series completas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operaciones b√°sicas con strings\n",
    "productos_ejemplo = pd.Series(['laptop hp', 'MOUSE logitech', 'Teclado Mec√°nico', 'Monitor DELL'])\n",
    "\n",
    "print(\"Strings originales:\")\n",
    "print(productos_ejemplo)\n",
    "\n",
    "print(\"\\nMin√∫sculas:\")\n",
    "print(productos_ejemplo.str.lower())\n",
    "\n",
    "print(\"\\nMay√∫sculas:\")\n",
    "print(productos_ejemplo.str.upper())\n",
    "\n",
    "print(\"\\nCapitalizar primera letra:\")\n",
    "print(productos_ejemplo.str.capitalize())\n",
    "\n",
    "print(\"\\nTitle case (cada palabra capitalizada):\")\n",
    "print(productos_ejemplo.str.title())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B√∫squeda y reemplazo\n",
    "print(\"Productos que contienen 'o':\")\n",
    "print(productos_ejemplo.str.contains('o', case=False))\n",
    "\n",
    "print(\"\\nFiltrar productos que contienen 'o':\")\n",
    "print(productos_ejemplo[productos_ejemplo.str.contains('o', case=False)])\n",
    "\n",
    "# Reemplazar texto\n",
    "productos_limpio = productos_ejemplo.str.replace('hp', 'HP').str.replace('logitech', 'Logitech')\n",
    "print(\"\\nDespu√©s de reemplazar marcas:\")\n",
    "print(productos_limpio)\n",
    "\n",
    "# Split (dividir)\n",
    "print(\"\\nDividir por espacios (primera palabra):\")\n",
    "print(productos_ejemplo.str.split().str[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Operaciones con Fechas (.dt accessor)\n",
    "\n",
    "El accessor `.dt` nos da acceso a propiedades y m√©todos de fechas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya tenemos columna 'fecha' en ventas_df\n",
    "# Extraer componentes de fecha\n",
    "ventas_df['a√±o'] = ventas_df['fecha'].dt.year\n",
    "ventas_df['mes'] = ventas_df['fecha'].dt.month\n",
    "ventas_df['dia'] = ventas_df['fecha'].dt.day\n",
    "ventas_df['hora'] = ventas_df['fecha'].dt.hour\n",
    "ventas_df['dia_semana'] = ventas_df['fecha'].dt.day_name()\n",
    "\n",
    "print(\"Componentes de fecha extra√≠dos:\")\n",
    "print(ventas_df[['fecha', 'a√±o', 'mes', 'dia', 'hora', 'dia_semana']].head())\n",
    "\n",
    "# Ventas por d√≠a de la semana\n",
    "ventas_por_dia_semana = ventas_df.groupby('dia_semana')['ingreso_total'].sum().sort_values(ascending=False)\n",
    "print(\"\\nVentas por d√≠a de la semana:\")\n",
    "print(ventas_por_dia_semana.apply(lambda x: f\"${x:,.2f}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operaciones con per√≠odos\n",
    "ventas_df['trimestre'] = ventas_df['fecha'].dt.quarter\n",
    "ventas_df['semana_a√±o'] = ventas_df['fecha'].dt.isocalendar().week\n",
    "\n",
    "print(\"Ventas por trimestre:\")\n",
    "ventas_trimestre = ventas_df.groupby('trimestre')['ingreso_total'].sum()\n",
    "print(ventas_trimestre.apply(lambda x: f\"${x:,.2f}\"))\n",
    "\n",
    "# Calcular antig√ºedad\n",
    "fecha_hoy = pd.Timestamp('2023-02-01')\n",
    "ventas_df['dias_desde_venta'] = (fecha_hoy - ventas_df['fecha']).dt.days\n",
    "\n",
    "print(f\"\\nRango de antig√ºedad de ventas: {ventas_df['dias_desde_venta'].min()} a {ventas_df['dias_desde_venta'].max()} d√≠as\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Manejo de Valores Faltantes\n",
    "\n",
    "Los datos reales casi siempre tienen valores faltantes. Pandas ofrece herramientas para detectarlos y tratarlos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datos con valores faltantes para demostraci√≥n\n",
    "df_con_nulos = pd.DataFrame({\n",
    "    'producto': ['Laptop', 'Mouse', None, 'Monitor', 'Teclado'],\n",
    "    'precio': [1000, 25, 350, None, 85],\n",
    "    'stock': [5, None, 15, 8, 12],\n",
    "    'categoria': ['Computadoras', 'Accesorios', 'Accesorios', 'Computadoras', None]\n",
    "})\n",
    "\n",
    "print(\"DataFrame con valores faltantes:\")\n",
    "print(df_con_nulos)\n",
    "\n",
    "# Detectar valores faltantes\n",
    "print(\"\\n¬øHay valores faltantes por columna?\")\n",
    "print(df_con_nulos.isna().sum())\n",
    "\n",
    "print(\"\\n¬øHay valores NO faltantes por columna?\")\n",
    "print(df_con_nulos.notna().sum())\n",
    "\n",
    "# Porcentaje de valores faltantes\n",
    "print(\"\\nPorcentaje de valores faltantes:\")\n",
    "print((df_con_nulos.isna().sum() / len(df_con_nulos) * 100).round(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con valores faltantes\n",
    "df_sin_nulos = df_con_nulos.dropna()\n",
    "print(f\"Original: {len(df_con_nulos)} filas\")\n",
    "print(f\"Sin nulos: {len(df_sin_nulos)} filas\")\n",
    "print(\"\\nDataFrame sin nulos:\")\n",
    "print(df_sin_nulos)\n",
    "\n",
    "# Eliminar columnas con valores faltantes\n",
    "df_sin_columnas_nulas = df_con_nulos.dropna(axis=1)\n",
    "print(f\"\\nColumnas originales: {list(df_con_nulos.columns)}\")\n",
    "print(f\"Columnas sin nulos: {list(df_sin_columnas_nulas.columns)}\")\n",
    "\n",
    "# Imputar (rellenar) valores faltantes\n",
    "# Estrategia 1: Valor constante\n",
    "df_imputado = df_con_nulos.fillna({\n",
    "    'producto': 'Desconocido',\n",
    "    'precio': df_con_nulos['precio'].median(),\n",
    "    'stock': 0,\n",
    "    'categoria': 'Sin categor√≠a'\n",
    "})\n",
    "print(\"\\nDataFrame con valores imputados:\")\n",
    "print(df_imputado)\n",
    "\n",
    "# Estrategia 2: Forward fill (propagar valor anterior)\n",
    "df_ffill = df_con_nulos.fillna(method='ffill')\n",
    "print(\"\\nCon forward fill:\")\n",
    "print(df_ffill)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 Ordenamiento\n",
    "\n",
    "Ordenar datos es fundamental para an√°lisis y presentaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por una columna\n",
    "ventas_ordenadas = ventas_df.sort_values('ingreso_total', ascending=False)\n",
    "print(\"Top 10 transacciones por ingreso:\")\n",
    "print(ventas_ordenadas[['fecha', 'producto', 'cantidad', 'precio_unitario', 'ingreso_total']].head(10))\n",
    "\n",
    "# Ordenar por m√∫ltiples columnas\n",
    "ventas_multi_orden = ventas_df.sort_values(['region', 'ingreso_total'], ascending=[True, False])\n",
    "print(\"\\nPrimeras transacciones ordenadas por regi√≥n (asc) e ingreso (desc):\")\n",
    "print(ventas_multi_orden[['region', 'producto', 'ingreso_total']].head(10))\n",
    "\n",
    "# Ordenar por √≠ndice\n",
    "ventas_df_reset = ventas_df.reset_index(drop=True)\n",
    "ventas_ordenadas_idx = ventas_df_reset.sort_index(ascending=False)\n",
    "print(f\"\\nPrimeras filas despu√©s de ordenar por √≠ndice descendente:\")\n",
    "print(ventas_ordenadas_idx[['producto', 'ingreso_total']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 Joins y Merges\n",
    "\n",
    "Combinar m√∫ltiples datasets es una operaci√≥n fundamental en an√°lisis de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya tenemos clientes_df creado anteriormente\n",
    "# Agreguemos una tabla de inventario para demostrar joins\n",
    "inventario_df = pd.DataFrame({\n",
    "    'producto': ['Laptop', 'Mouse', 'Teclado', 'Monitor', 'Aud√≠fonos', 'Webcam', 'Impresora'],\n",
    "    'stock_actual': [15, 120, 45, 22, 67, 34, 8],\n",
    "    'stock_minimo': [5, 30, 15, 10, 20, 10, 5],\n",
    "    'proveedor': ['Proveedor A', 'Proveedor B', 'Proveedor B', 'Proveedor A', 'Proveedor C', 'Proveedor B', 'Proveedor A']\n",
    "})\n",
    "\n",
    "print(\"Dataset de inventario:\")\n",
    "print(inventario_df)\n",
    "\n",
    "# Calcular ventas totales por producto\n",
    "ventas_por_producto = ventas_df.groupby('producto').agg({\n",
    "    'cantidad': 'sum',\n",
    "    'ingreso_total': 'sum'\n",
    "}).reset_index()\n",
    "ventas_por_producto.columns = ['producto', 'unidades_vendidas', 'ingreso_total']\n",
    "\n",
    "print(\"\\nVentas por producto:\")\n",
    "print(ventas_por_producto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INNER JOIN: Solo productos que est√°n en ambas tablas\n",
    "inner_join = pd.merge(ventas_por_producto, inventario_df, on='producto', how='inner')\n",
    "print(\"INNER JOIN (productos en ambas tablas):\")\n",
    "print(inner_join)\n",
    "print(f\"Registros: {len(inner_join)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT JOIN: Todos los productos de ventas, con info de inventario si existe\n",
    "left_join = pd.merge(ventas_por_producto, inventario_df, on='producto', how='left')\n",
    "print(\"LEFT JOIN (todas las ventas, con inventario si existe):\")\n",
    "print(left_join)\n",
    "print(f\"Registros: {len(left_join)}\")\n",
    "\n",
    "# RIGHT JOIN: Todos los productos de inventario, con ventas si existen\n",
    "right_join = pd.merge(ventas_por_producto, inventario_df, on='producto', how='right')\n",
    "print(\"\\nRIGHT JOIN (todo el inventario, con ventas si existen):\")\n",
    "print(right_join)\n",
    "print(f\"Registros: {len(right_join)}\")\n",
    "\n",
    "# OUTER JOIN: Todos los productos de ambas tablas\n",
    "outer_join = pd.merge(ventas_por_producto, inventario_df, on='producto', how='outer')\n",
    "print(\"\\nOUTER JOIN (uni√≥n de ambas tablas):\")\n",
    "print(outer_join)\n",
    "print(f\"Registros: {len(outer_join)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join de ventas con clientes\n",
    "# Primero calculamos ventas por cliente\n",
    "ventas_por_cliente = ventas_df.groupby('cliente_id').agg({\n",
    "    'ingreso_total': 'sum',\n",
    "    'fecha': 'count'  # N√∫mero de transacciones\n",
    "}).reset_index()\n",
    "ventas_por_cliente.columns = ['cliente_id', 'valor_total_compras', 'num_transacciones']\n",
    "\n",
    "# Hacer join con datos de clientes\n",
    "clientes_con_ventas = pd.merge(clientes_df, ventas_por_cliente, on='cliente_id', how='left')\n",
    "\n",
    "# Rellenar NaN con 0 para clientes sin compras\n",
    "clientes_con_ventas['valor_total_compras'] = clientes_con_ventas['valor_total_compras'].fillna(0)\n",
    "clientes_con_ventas['num_transacciones'] = clientes_con_ventas['num_transacciones'].fillna(0)\n",
    "\n",
    "print(\"Clientes con informaci√≥n de ventas:\")\n",
    "print(clientes_con_ventas.head(10))\n",
    "\n",
    "print(f\"\\nClientes sin compras: {(clientes_con_ventas['num_transacciones'] == 0).sum()}\")\n",
    "print(f\"Clientes con compras: {(clientes_con_ventas['num_transacciones'] > 0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12 Operaciones Avanzadas\n",
    "\n",
    "Finalmente, veamos algunas operaciones avanzadas muy √∫tiles en an√°lisis de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding de variables categ√≥ricas\n",
    "categorias_encoded = pd.get_dummies(ventas_df['categoria'], prefix='cat')\n",
    "print(\"One-hot encoding de categor√≠as:\")\n",
    "print(categorias_encoded.head())\n",
    "\n",
    "# Combinar con el DataFrame original\n",
    "ventas_encoded = pd.concat([ventas_df, categorias_encoded], axis=1)\n",
    "print(f\"\\nDataFrame con one-hot encoding: {ventas_encoded.shape}\")\n",
    "print(ventas_encoded[['categoria', 'cat_Accesorios', 'cat_Computadoras', 'cat_Electr√≥nica']].head())\n",
    "\n",
    "# Label encoding (menos recomendado para variables sin orden)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "ventas_df['categoria_codigo'] = le.fit_transform(ventas_df['categoria'])\n",
    "print(\"\\nLabel encoding de categor√≠as:\")\n",
    "print(ventas_df[['categoria', 'categoria_codigo']].drop_duplicates().sort_values('categoria_codigo'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling windows (ventanas m√≥viles) - √∫til para series temporales\n",
    "# Calcular media m√≥vil de 7 transacciones\n",
    "ventas_sorted = ventas_df.sort_values('fecha').reset_index(drop=True)\n",
    "ventas_sorted['media_movil_7'] = ventas_sorted['ingreso_total'].rolling(window=7).mean()\n",
    "\n",
    "print(\"Media m√≥vil de 7 transacciones:\")\n",
    "print(ventas_sorted[['fecha', 'ingreso_total', 'media_movil_7']].head(15).round(2))\n",
    "\n",
    "# Acumulados\n",
    "ventas_sorted['ingreso_acumulado'] = ventas_sorted['ingreso_total'].cumsum()\n",
    "print(f\"\\nIngreso acumulado final: ${ventas_sorted['ingreso_acumulado'].iloc[-1]:,.2f}\")\n",
    "\n",
    "# Ver primeras transacciones con acumulado\n",
    "print(ventas_sorted[['fecha', 'ingreso_total', 'ingreso_acumulado']].head(10).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot tables (tablas din√°micas)\n",
    "pivot_region_producto = pd.pivot_table(\n",
    "    ventas_df,\n",
    "    values='ingreso_total',\n",
    "    index='region',\n",
    "    columns='categoria',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0,\n",
    "    margins=True,  # Agregar totales\n",
    "    margins_name='TOTAL'\n",
    ")\n",
    "\n",
    "print(\"Tabla pivote: Ingresos por regi√≥n y categor√≠a\")\n",
    "print(pivot_region_producto.round(0))\n",
    "\n",
    "# Pivot table con m√∫ltiples agregaciones\n",
    "pivot_multi = pd.pivot_table(\n",
    "    ventas_df,\n",
    "    values='ingreso_total',\n",
    "    index='region',\n",
    "    columns='categoria',\n",
    "    aggfunc=['sum', 'mean', 'count'],\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(\"\\nPivot table con m√∫ltiples agregaciones (primeras filas):\")\n",
    "print(pivot_multi.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Visualizaci√≥n de Datos\n",
    "\n",
    "**Objetivos de aprendizaje:**\n",
    "- Crear gr√°ficos b√°sicos con Matplotlib\n",
    "- Personalizar visualizaciones (t√≠tulos, etiquetas, colores, leyendas)\n",
    "- Utilizar Seaborn para visualizaciones estad√≠sticas avanzadas\n",
    "- Elegir el tipo de gr√°fico apropiado para cada an√°lisis\n",
    "\n",
    "**Conceptos clave**: matplotlib, seaborn, tipos de gr√°ficos, est√©tica, visualizaci√≥n exploratoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Matplotlib B√°sico\n",
    "\n",
    "Matplotlib es la librer√≠a fundamental de visualizaci√≥n en Python. Proporciona control total sobre cada aspecto del gr√°fico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anatom√≠a de una figura en Matplotlib\n",
    "fig, ax = plt.subplots(figsize=(10, 6))  # fig = figura completa, ax = √°rea del gr√°fico\n",
    "\n",
    "# Crear datos\n",
    "meses = ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun']\n",
    "ventas_2022 = [45, 52, 48, 61, 58, 65]\n",
    "ventas_2023 = [52, 58, 55, 68, 72, 79]\n",
    "\n",
    "# Gr√°fico de l√≠nea\n",
    "ax.plot(meses, ventas_2022, marker='o', linewidth=2, label='2022')\n",
    "ax.plot(meses, ventas_2023, marker='s', linewidth=2, label='2023')\n",
    "\n",
    "# Personalizaci√≥n\n",
    "ax.set_title('Evoluci√≥n de Ventas 2022 vs 2023', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Mes', fontsize=12)\n",
    "ax.set_ylabel('Ventas (miles de $)', fontsize=12)\n",
    "ax.legend(fontsize=10, loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√∫ltiples subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Subplot 1: Ventas por regi√≥n\n",
    "ventas_region = ventas_df.groupby('region')['ingreso_total'].sum().sort_values(ascending=False)\n",
    "axes[0, 0].bar(ventas_region.index, ventas_region.values, color='steelblue')\n",
    "axes[0, 0].set_title('Ventas Totales por Regi√≥n')\n",
    "axes[0, 0].set_ylabel('Ingresos ($)')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Subplot 2: Productos m√°s vendidos\n",
    "top_productos = ventas_df.groupby('producto')['cantidad'].sum().sort_values(ascending=False).head(6)\n",
    "axes[0, 1].barh(top_productos.index, top_productos.values, color='coral')\n",
    "axes[0, 1].set_title('Top 6 Productos por Unidades Vendidas')\n",
    "axes[0, 1].set_xlabel('Cantidad')\n",
    "\n",
    "# Subplot 3: Distribuci√≥n de ingresos\n",
    "axes[1, 0].hist(ventas_df['ingreso_total'], bins=30, color='green', alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_title('Distribuci√≥n de Ingresos por Transacci√≥n')\n",
    "axes[1, 0].set_xlabel('Ingreso ($)')\n",
    "axes[1, 0].set_ylabel('Frecuencia')\n",
    "\n",
    "# Subplot 4: Scatter de precio vs cantidad\n",
    "axes[1, 1].scatter(ventas_df['precio_unitario'], ventas_df['cantidad'], alpha=0.5, c='purple')\n",
    "axes[1, 1].set_title('Precio Unitario vs Cantidad')\n",
    "axes[1, 1].set_xlabel('Precio Unitario ($)')\n",
    "axes[1, 1].set_ylabel('Cantidad')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar figuras\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Ventas por categor√≠a\n",
    "ventas_categoria = ventas_df.groupby('categoria')['ingreso_total'].sum()\n",
    "colores = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "ax.pie(ventas_categoria.values, labels=ventas_categoria.index, autopct='%1.1f%%', \n",
    "       startangle=90, colors=colores, explode=(0.05, 0, 0))\n",
    "ax.set_title('Distribuci√≥n de Ventas por Categor√≠a', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar en diferentes formatos (comentado para no crear archivos)\n",
    "# plt.savefig('ventas_categoria.png', dpi=300, bbox_inches='tight')\n",
    "# plt.savefig('ventas_categoria.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Tipos de Gr√°ficos con Matplotlib\n",
    "\n",
    "Cada tipo de gr√°fico es apropiado para diferentes situaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°ficos de dispersi√≥n (scatter plots)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Colorear por categor√≠a\n",
    "categorias = ventas_df['categoria'].unique()\n",
    "colores_map = {'Electr√≥nica': 'red', 'Accesorios': 'blue', 'Computadoras': 'green'}\n",
    "\n",
    "for cat in categorias:\n",
    "    datos = ventas_df[ventas_df['categoria'] == cat]\n",
    "    ax.scatter(datos['precio_unitario'], datos['ingreso_total'], \n",
    "               alpha=0.6, s=50, label=cat, c=colores_map[cat])\n",
    "\n",
    "ax.set_xlabel('Precio Unitario ($)', fontsize=12)\n",
    "ax.set_ylabel('Ingreso Total ($)', fontsize=12)\n",
    "ax.set_title('Relaci√≥n entre Precio Unitario e Ingreso Total', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°ficos de barras con comparaci√≥n\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Comparar ventas por regi√≥n y categor√≠a\n",
    "comparacion = ventas_df.groupby(['region', 'categoria'])['ingreso_total'].sum().unstack()\n",
    "\n",
    "x = np.arange(len(comparacion.index))\n",
    "width = 0.25\n",
    "\n",
    "for i, col in enumerate(comparacion.columns):\n",
    "    ax.bar(x + i*width, comparacion[col], width, label=col)\n",
    "\n",
    "ax.set_xlabel('Regi√≥n', fontsize=12)\n",
    "ax.set_ylabel('Ingresos ($)', fontsize=12)\n",
    "ax.set_title('Ventas por Regi√≥n y Categor√≠a', fontsize=14)\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(comparacion.index)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas con personalizaci√≥n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histograma b√°sico\n",
    "axes[0].hist(ventas_df['ingreso_total'], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Ingreso Total ($)')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].set_title('Distribuci√≥n de Ingresos')\n",
    "axes[0].axvline(ventas_df['ingreso_total'].mean(), color='red', linestyle='--', linewidth=2, label='Media')\n",
    "axes[0].axvline(ventas_df['ingreso_total'].median(), color='green', linestyle='--', linewidth=2, label='Mediana')\n",
    "axes[0].legend()\n",
    "\n",
    "# Histograma por categor√≠a\n",
    "for cat in ventas_df['categoria'].unique():\n",
    "    datos = ventas_df[ventas_df['categoria'] == cat]['ingreso_total']\n",
    "    axes[1].hist(datos, bins=30, alpha=0.5, label=cat, edgecolor='black')\n",
    "\n",
    "axes[1].set_xlabel('Ingreso Total ($)')\n",
    "axes[1].set_ylabel('Frecuencia')\n",
    "axes[1].set_title('Distribuci√≥n de Ingresos por Categor√≠a')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots (diagramas de caja)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Boxplot de ingresos por regi√≥n\n",
    "datos_boxplot = [ventas_df[ventas_df['region'] == r]['ingreso_total'].values \n",
    "                 for r in ventas_df['region'].unique()]\n",
    "axes[0].boxplot(datos_boxplot, labels=ventas_df['region'].unique())\n",
    "axes[0].set_xlabel('Regi√≥n')\n",
    "axes[0].set_ylabel('Ingreso Total ($)')\n",
    "axes[0].set_title('Distribuci√≥n de Ingresos por Regi√≥n')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Boxplot horizontal de productos\n",
    "productos_orden = ventas_df.groupby('producto')['ingreso_total'].median().sort_values(ascending=False).index\n",
    "datos_productos = [ventas_df[ventas_df['producto'] == p]['ingreso_total'].values \n",
    "                   for p in productos_orden]\n",
    "bp = axes[1].boxplot(datos_productos, labels=productos_orden, vert=False, patch_artist=True)\n",
    "\n",
    "# Colorear cajas\n",
    "colores = plt.cm.Set3(np.linspace(0, 1, len(productos_orden)))\n",
    "for patch, color in zip(bp['boxes'], colores):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "axes[1].set_xlabel('Ingreso Total ($)')\n",
    "axes[1].set_ylabel('Producto')\n",
    "axes[1].set_title('Distribuci√≥n de Ingresos por Producto')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretaci√≥n del boxplot:\")\n",
    "print(\"  - Caja: rango intercuart√≠lico (Q1 a Q3)\")\n",
    "print(\"  - L√≠nea en la caja: mediana\")\n",
    "print(\"  - Bigotes: 1.5 √ó IQR\")\n",
    "print(\"  - Puntos fuera: valores at√≠picos (outliers)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Seaborn - Visualizaci√≥n Estad√≠stica\n",
    "\n",
    "Seaborn est√° construido sobre Matplotlib y proporciona interfaces de alto nivel para crear gr√°ficos estad√≠sticos atractivos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¬øPor qu√© Seaborn?\n",
    "# 1. Est√©tica mejorada autom√°ticamente\n",
    "# 2. Funciones estad√≠sticas integradas\n",
    "# 3. Trabajo m√°s f√°cil con DataFrames de Pandas\n",
    "# 4. Paletas de colores profesionales\n",
    "\n",
    "# Comparaci√≥n Matplotlib vs Seaborn\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Matplotlib\n",
    "axes[0].scatter(ventas_df['precio_unitario'], ventas_df['ingreso_total'], alpha=0.5)\n",
    "axes[0].set_title('Con Matplotlib')\n",
    "axes[0].set_xlabel('Precio Unitario')\n",
    "axes[0].set_ylabel('Ingreso Total')\n",
    "\n",
    "# Seaborn\n",
    "sns.scatterplot(data=ventas_df, x='precio_unitario', y='ingreso_total', \n",
    "                hue='categoria', size='cantidad', alpha=0.6, ax=axes[1])\n",
    "axes[1].set_title('Con Seaborn')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuciones con Seaborn\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Histplot con KDE\n",
    "sns.histplot(data=ventas_df, x='ingreso_total', kde=True, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Histograma con KDE (Kernel Density Estimation)')\n",
    "\n",
    "# Histplot por categor√≠a\n",
    "sns.histplot(data=ventas_df, x='ingreso_total', hue='categoria', kde=True, ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Histograma por Categor√≠a')\n",
    "\n",
    "# KDE plot\n",
    "sns.kdeplot(data=ventas_df, x='ingreso_total', hue='region', fill=True, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Distribuci√≥n de Densidad por Regi√≥n')\n",
    "\n",
    "# Violinplot\n",
    "sns.violinplot(data=ventas_df, x='categoria', y='ingreso_total', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Violinplot de Ingresos por Categor√≠a')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°ficos de relaciones con Seaborn\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Scatterplot con m√∫ltiples dimensiones\n",
    "sns.scatterplot(data=ventas_df, x='precio_unitario', y='ingreso_total', \n",
    "                hue='categoria', size='cantidad', style='region', \n",
    "                alpha=0.6, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Scatterplot Multi-dimensional')\n",
    "axes[0, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "\n",
    "# Lineplot con intervalos de confianza\n",
    "ventas_por_hora = ventas_df.groupby('hora')['ingreso_total'].mean().reset_index()\n",
    "sns.lineplot(data=ventas_por_hora, x='hora', y='ingreso_total', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Ventas Promedio por Hora del D√≠a')\n",
    "axes[0, 1].set_xlabel('Hora')\n",
    "\n",
    "# Regplot (regresi√≥n lineal)\n",
    "sns.regplot(data=ventas_df, x='precio_unitario', y='cantidad', \n",
    "            scatter_kws={'alpha': 0.3}, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Relaci√≥n Precio-Cantidad con L√≠nea de Tendencia')\n",
    "\n",
    "# Hexbin plot (para muchos datos)\n",
    "axes[1, 1].hexbin(ventas_df['precio_unitario'], ventas_df['ingreso_total'], \n",
    "                  gridsize=20, cmap='YlOrRd')\n",
    "axes[1, 1].set_title('Hexbin Plot (densidad de puntos)')\n",
    "axes[1, 1].set_xlabel('Precio Unitario')\n",
    "axes[1, 1].set_ylabel('Ingreso Total')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°ficos categ√≥ricos con Seaborn\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Barplot con errores est√°ndar\n",
    "sns.barplot(data=ventas_df, x='region', y='ingreso_total', errorbar='sd', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Ingresos por Regi√≥n (con desv. est√°ndar)')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Countplot\n",
    "sns.countplot(data=ventas_df, x='categoria', hue='region', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('N√∫mero de Transacciones por Categor√≠a y Regi√≥n')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Boxplot con Seaborn\n",
    "sns.boxplot(data=ventas_df, x='categoria', y='ingreso_total', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Boxplot de Ingresos por Categor√≠a')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Swarmplot (puntos individuales)\n",
    "# Nota: Solo usar con datasets peque√±os\n",
    "muestra = ventas_df.groupby('region').sample(n=20, random_state=42)\n",
    "sns.swarmplot(data=muestra, x='region', y='ingreso_total', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Swarmplot de Ingresos (muestra de 20 por regi√≥n)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices y correlaciones\n",
    "# Calcular matriz de correlaci√≥n\n",
    "columnas_numericas = ['cantidad', 'precio_unitario', 'ingreso_total']\n",
    "correlacion = ventas_df[columnas_numericas].corr()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Heatmap de correlaci√≥n\n",
    "sns.heatmap(correlacion, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, ax=axes[0])\n",
    "axes[0].set_title('Matriz de Correlaci√≥n')\n",
    "\n",
    "# Heatmap de pivot table\n",
    "pivot = pd.pivot_table(ventas_df, values='ingreso_total', \n",
    "                       index='region', columns='categoria', aggfunc='sum')\n",
    "sns.heatmap(pivot, annot=True, fmt='.0f', cmap='YlGnBu', ax=axes[1])\n",
    "axes[1].set_title('Ingresos por Regi√≥n y Categor√≠a')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot - Exploraci√≥n multivariada\n",
    "# Crear un subset m√°s peque√±o para pairplot (es computacionalmente costoso)\n",
    "ventas_sample = ventas_df.sample(n=200, random_state=42)\n",
    "\n",
    "# Pairplot con todas las variables num√©ricas\n",
    "pairplot = sns.pairplot(ventas_sample[['cantidad', 'precio_unitario', 'ingreso_total', 'categoria']], \n",
    "                        hue='categoria', diag_kind='kde', plot_kws={'alpha': 0.6})\n",
    "pairplot.fig.suptitle('Pairplot de Variables Num√©ricas', y=1.02)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEl pairplot muestra:\")\n",
    "print(\"  - Diagonal: distribuci√≥n de cada variable\")\n",
    "print(\"  - Fuera de diagonal: relaci√≥n entre pares de variables\")\n",
    "print(\"  - Colores: diferentes categor√≠as\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facet Grid - M√∫ltiples subplots basados en variables categ√≥ricas\n",
    "g = sns.FacetGrid(ventas_df, col='categoria', row='region', height=3, aspect=1.2)\n",
    "g.map(sns.histplot, 'ingreso_total', bins=20, kde=True)\n",
    "g.set_axis_labels('Ingreso Total ($)', 'Frecuencia')\n",
    "g.set_titles(col_template='{col_name}', row_template='{row_name}')\n",
    "g.add_legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Cada subplot muestra la distribuci√≥n de ingresos para una combinaci√≥n regi√≥n-categor√≠a\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Caso Integrador: An√°lisis de Datos Reales\n",
    "\n",
    "**Objetivos de aprendizaje:**\n",
    "- Aplicar todas las t√©cnicas aprendidas en un caso real\n",
    "- Realizar un an√°lisis exploratorio completo\n",
    "- Limpiar y preparar datos con problemas reales\n",
    "- Generar insights accionables de negocio\n",
    "\n",
    "**Dataset**: Simulaci√≥n basada en Online Retail Dataset (UCI)\n",
    "\n",
    "En esta secci√≥n aplicaremos todo lo aprendido a un dataset que simula transacciones reales de e-commerce, con problemas t√≠picos como valores faltantes, datos duplicados y outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Carga y Exploraci√≥n Inicial del Dataset\n",
    "\n",
    "Primero cargaremos y exploraremos el dataset para entender su estructura y calidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar datos sint√©ticos realistas que simulan Online Retail\n",
    "# Este dataset simula transacciones de e-commerce con caracter√≠sticas reales\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Par√°metros del dataset\n",
    "n_transacciones = 5000\n",
    "n_clientes = 500\n",
    "n_productos = 100\n",
    "\n",
    "# Generar IDs de factura\n",
    "invoice_ids = [f'INV{str(i).zfill(6)}' for i in range(1, n_transacciones + 1)]\n",
    "\n",
    "# Generar productos con descripciones realistas\n",
    "productos_base = [\n",
    "    'WHITE HANGING HEART T-LIGHT HOLDER', 'WHITE METAL LANTERN', \n",
    "    'CREAM CUPID HEARTS COAT HANGER', 'KNITTED UNION FLAG HOT WATER BOTTLE',\n",
    "    'RED WOOLLY HOTTIE WHITE HEART', 'SET 7 BABUSHKA NESTING BOXES',\n",
    "    'GLASS STAR FROSTED T-LIGHT HOLDER', 'HAND WARMER UNION JACK',\n",
    "    'HAND WARMER RED POLKA DOT', 'ASSORTED COLOUR BIRD ORNAMENT',\n",
    "    'PACK OF 60 PINK PAISLEY CAKE CASES', 'PACK OF 60 DINOSAUR CAKE CASES',\n",
    "    'LUNCH BAG RED RETROSPOT', 'LUNCH BAG PINK POLKADOT',\n",
    "    'SET OF 3 CAKE TINS PANTRY DESIGN', 'JUMBO BAG RED RETROSPOT'\n",
    "]\n",
    "productos = np.random.choice(productos_base, n_transacciones)\n",
    "\n",
    "# Generar cantidades (mayor√≠a positivas, algunas negativas para devoluciones)\n",
    "cantidades = np.random.choice(\n",
    "    list(range(-3, 0)) + list(range(1, 25)), \n",
    "    n_transacciones, \n",
    "    p=[0.01, 0.01, 0.01] + [0.97/24]*24  # 3% devoluciones\n",
    ")\n",
    "\n",
    "# Generar precios unitarios (con algunos valores problem√°ticos)\n",
    "precios_base = np.random.uniform(0.5, 50, n_transacciones)\n",
    "# Algunos productos con precio 0 (problema de calidad de datos)\n",
    "mask_precio_cero = np.random.random(n_transacciones) < 0.02\n",
    "precios_base[mask_precio_cero] = 0\n",
    "\n",
    "# Fechas\n",
    "fechas = pd.date_range('2023-01-01', periods=n_transacciones, freq='H')\n",
    "\n",
    "# Clientes (con algunos faltantes)\n",
    "customer_ids = np.random.choice(range(1000, 1000 + n_clientes), n_transacciones)\n",
    "mask_cliente_faltante = np.random.random(n_transacciones) < 0.15  # 15% sin cliente\n",
    "customer_ids = customer_ids.astype(float)\n",
    "customer_ids[mask_cliente_faltante] = np.nan\n",
    "\n",
    "# Pa√≠ses\n",
    "paises = np.random.choice(\n",
    "    ['United Kingdom', 'Germany', 'France', 'Spain', 'Netherlands', 'Belgium', 'Portugal'],\n",
    "    n_transacciones,\n",
    "    p=[0.75, 0.08, 0.06, 0.04, 0.03, 0.02, 0.02]\n",
    ")\n",
    "\n",
    "# Crear DataFrame\n",
    "retail_df = pd.DataFrame({\n",
    "    'InvoiceNo': invoice_ids,\n",
    "    'StockCode': [f'SKU{np.random.randint(1000, 9999)}' for _ in range(n_transacciones)],\n",
    "    'Description': productos,\n",
    "    'Quantity': cantidades,\n",
    "    'InvoiceDate': fechas,\n",
    "    'UnitPrice': precios_base.round(2),\n",
    "    'CustomerID': customer_ids,\n",
    "    'Country': paises\n",
    "})\n",
    "\n",
    "print(\"‚úì Dataset sint√©tico de e-commerce creado\")\n",
    "print(f\"\\nDimensiones: {retail_df.shape}\")\n",
    "print(f\"\\nPrimeras filas:\")\n",
    "print(retail_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n inicial\n",
    "print(\"Informaci√≥n general del dataset:\")\n",
    "print(retail_df.info())\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Estad√≠sticas descriptivas:\")\n",
    "print(retail_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar problemas de calidad de datos\n",
    "print(\"AN√ÅLISIS DE CALIDAD DE DATOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. Valores faltantes:\")\n",
    "print(retail_df.isnull().sum())\n",
    "print(f\"\\nPorcentaje de CustomerID faltantes: {retail_df['CustomerID'].isnull().sum() / len(retail_df) * 100:.1f}%\")\n",
    "\n",
    "print(\"\\n2. Valores problem√°ticos:\")\n",
    "print(f\"  - Cantidades negativas (devoluciones): {(retail_df['Quantity'] < 0).sum()}\")\n",
    "print(f\"  - Precios igual a 0: {(retail_df['UnitPrice'] == 0).sum()}\")\n",
    "print(f\"  - Productos √∫nicos: {retail_df['Description'].nunique()}\")\n",
    "print(f\"  - Clientes √∫nicos: {retail_df['CustomerID'].nunique()}\")\n",
    "\n",
    "print(\"\\n3. Rango de fechas:\")\n",
    "print(f\"  - Inicio: {retail_df['InvoiceDate'].min()}\")\n",
    "print(f\"  - Fin: {retail_df['InvoiceDate'].max()}\")\n",
    "print(f\"  - Duraci√≥n: {(retail_df['InvoiceDate'].max() - retail_df['InvoiceDate'].min()).days} d√≠as\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Limpieza de Datos\n",
    "\n",
    "Aplicaremos t√©cnicas de limpieza para preparar los datos para an√°lisis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Crear columna de ingreso total\n",
    "retail_df['TotalPrice'] = retail_df['Quantity'] * retail_df['UnitPrice']\n",
    "\n",
    "# Paso 2: Filtrar registros problem√°ticos\n",
    "print(\"Limpieza de datos:\")\n",
    "print(f\"Registros originales: {len(retail_df)}\")\n",
    "\n",
    "# Eliminar transacciones con cantidad negativa (devoluciones)\n",
    "retail_clean = retail_df[retail_df['Quantity'] > 0].copy()\n",
    "print(f\"Despu√©s de eliminar devoluciones: {len(retail_clean)}\")\n",
    "\n",
    "# Eliminar transacciones con precio 0\n",
    "retail_clean = retail_clean[retail_clean['UnitPrice'] > 0]\n",
    "print(f\"Despu√©s de eliminar precios inv√°lidos: {len(retail_clean)}\")\n",
    "\n",
    "# Para este an√°lisis, eliminaremos registros sin CustomerID\n",
    "retail_clean = retail_clean[retail_clean['CustomerID'].notna()]\n",
    "print(f\"Despu√©s de eliminar registros sin cliente: {len(retail_clean)}\")\n",
    "\n",
    "# Convertir CustomerID a entero\n",
    "retail_clean['CustomerID'] = retail_clean['CustomerID'].astype(int)\n",
    "\n",
    "print(f\"\\n‚úì Dataset limpio: {retail_clean.shape}\")\n",
    "print(f\"P√©rdida de datos: {(1 - len(retail_clean)/len(retail_df))*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 3: Crear features de fecha\n",
    "retail_clean['Year'] = retail_clean['InvoiceDate'].dt.year\n",
    "retail_clean['Month'] = retail_clean['InvoiceDate'].dt.month\n",
    "retail_clean['Day'] = retail_clean['InvoiceDate'].dt.day\n",
    "retail_clean['Hour'] = retail_clean['InvoiceDate'].dt.hour\n",
    "retail_clean['DayOfWeek'] = retail_clean['InvoiceDate'].dt.day_name()\n",
    "\n",
    "print(\"Features de fecha creadas:\")\n",
    "print(retail_clean[['InvoiceDate', 'Year', 'Month', 'Day', 'Hour', 'DayOfWeek']].head())\n",
    "\n",
    "# Identificar outliers con IQR\n",
    "Q1 = retail_clean['TotalPrice'].quantile(0.25)\n",
    "Q3 = retail_clean['TotalPrice'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outlier_threshold = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = retail_clean[retail_clean['TotalPrice'] > outlier_threshold]\n",
    "print(f\"\\nOutliers detectados (>Q3 + 1.5*IQR): {len(outliers)} ({len(outliers)/len(retail_clean)*100:.1f}%)\")\n",
    "print(f\"Umbral de outlier: ${outlier_threshold:,.2f}\")\n",
    "print(f\"\\nTop 5 transacciones m√°s grandes:\")\n",
    "print(retail_clean.nlargest(5, 'TotalPrice')[['Description', 'Quantity', 'UnitPrice', 'TotalPrice']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 An√°lisis Exploratorio de Datos (EDA)\n",
    "\n",
    "Ahora realizaremos un an√°lisis exploratorio completo para entender el negocio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de productos\n",
    "print(\"AN√ÅLISIS DE PRODUCTOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Top 10 productos por ingresos\n",
    "top_productos_ingresos = retail_clean.groupby('Description')['TotalPrice'].sum().sort_values(ascending=False).head(10)\n",
    "print(\"\\nTop 10 productos por ingresos totales:\")\n",
    "for i, (producto, ingreso) in enumerate(top_productos_ingresos.items(), 1):\n",
    "    print(f\"  {i}. {producto[:50]}: ${ingreso:,.2f}\")\n",
    "\n",
    "# Top 10 productos por cantidad vendida\n",
    "top_productos_cantidad = retail_clean.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(10)\n",
    "print(\"\\nTop 10 productos por unidades vendidas:\")\n",
    "for i, (producto, cantidad) in enumerate(top_productos_cantidad.items(), 1):\n",
    "    print(f\"  {i}. {producto[:50]}: {cantidad:,.0f} unidades\")\n",
    "\n",
    "# Precio promedio por producto\n",
    "precio_promedio_productos = retail_clean.groupby('Description')['UnitPrice'].mean().sort_values(ascending=False).head(10)\n",
    "print(\"\\nTop 10 productos por precio promedio:\")\n",
    "for i, (producto, precio) in enumerate(precio_promedio_productos.items(), 1):\n",
    "    print(f\"  {i}. {producto[:50]}: ${precio:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis temporal\n",
    "print(\"AN√ÅLISIS TEMPORAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ventas por mes\n",
    "ventas_mes = retail_clean.groupby('Month')['TotalPrice'].sum()\n",
    "print(\"\\nVentas por mes:\")\n",
    "for mes, venta in ventas_mes.items():\n",
    "    print(f\"  Mes {mes}: ${venta:,.2f}\")\n",
    "\n",
    "# Ventas por d√≠a de la semana\n",
    "ventas_dia_semana = retail_clean.groupby('DayOfWeek')['TotalPrice'].sum().sort_values(ascending=False)\n",
    "print(\"\\nVentas por d√≠a de la semana:\")\n",
    "for dia, venta in ventas_dia_semana.items():\n",
    "    print(f\"  {dia}: ${venta:,.2f}\")\n",
    "\n",
    "# Ventas por hora del d√≠a\n",
    "ventas_hora = retail_clean.groupby('Hour')['TotalPrice'].sum()\n",
    "hora_pico = ventas_hora.idxmax()\n",
    "print(f\"\\nHora pico de ventas: {hora_pico}:00 con ${ventas_hora.max():,.2f}\")\n",
    "\n",
    "# Transacciones por hora\n",
    "transacciones_hora = retail_clean.groupby('Hour').size()\n",
    "print(f\"\\nDistribuci√≥n de transacciones por hora:\")\n",
    "print(f\"  Hora m√°s activa: {transacciones_hora.idxmax()}:00 ({transacciones_hora.max()} transacciones)\")\n",
    "print(f\"  Hora menos activa: {transacciones_hora.idxmin()}:00 ({transacciones_hora.min()} transacciones)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis geogr√°fico\n",
    "print(\"AN√ÅLISIS GEOGR√ÅFICO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ventas por pa√≠s\n",
    "ventas_pais = retail_clean.groupby('Country').agg({\n",
    "    'TotalPrice': 'sum',\n",
    "    'InvoiceNo': 'nunique',\n",
    "    'CustomerID': 'nunique'\n",
    "}).sort_values('TotalPrice', ascending=False)\n",
    "\n",
    "ventas_pais.columns = ['Ingresos_Totales', 'Num_Facturas', 'Num_Clientes']\n",
    "\n",
    "print(\"\\nVentas por pa√≠s:\")\n",
    "print(ventas_pais)\n",
    "\n",
    "# Ticket promedio por pa√≠s\n",
    "ventas_pais['Ticket_Promedio'] = ventas_pais['Ingresos_Totales'] / ventas_pais['Num_Facturas']\n",
    "print(\"\\nTicket promedio por pa√≠s:\")\n",
    "print(ventas_pais['Ticket_Promedio'].sort_values(ascending=False).apply(lambda x: f\"${x:,.2f}\"))\n",
    "\n",
    "# Concentraci√≥n de ventas\n",
    "print(f\"\\n% de ventas en UK: {ventas_pais.loc['United Kingdom', 'Ingresos_Totales'] / ventas_pais['Ingresos_Totales'].sum() * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Visualizaciones del An√°lisis\n",
    "\n",
    "Finalmente, crearemos visualizaciones para comunicar los insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n 1: Serie temporal de ventas\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Ventas diarias\n",
    "ventas_diarias = retail_clean.groupby(retail_clean['InvoiceDate'].dt.date)['TotalPrice'].sum()\n",
    "axes[0].plot(ventas_diarias.index, ventas_diarias.values, linewidth=2, color='steelblue')\n",
    "axes[0].set_title('Evoluci√≥n de Ventas Diarias', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Fecha')\n",
    "axes[0].set_ylabel('Ingresos ($)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Ventas por hora\n",
    "ventas_hora = retail_clean.groupby('Hour')['TotalPrice'].sum()\n",
    "axes[1].bar(ventas_hora.index, ventas_hora.values, color='coral')\n",
    "axes[1].set_title('Distribuci√≥n de Ventas por Hora del D√≠a', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Hora')\n",
    "axes[1].set_ylabel('Ingresos ($)')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n 2: Top pa√≠ses y productos\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Top 10 pa√≠ses\n",
    "top_paises = ventas_pais.nlargest(10, 'Ingresos_Totales')\n",
    "axes[0].barh(range(len(top_paises)), top_paises['Ingresos_Totales'], color='#4ECDC4')\n",
    "axes[0].set_yticks(range(len(top_paises)))\n",
    "axes[0].set_yticklabels(top_paises.index)\n",
    "axes[0].set_title('Top 10 Pa√≠ses por Ingresos', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Ingresos ($)')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Top 10 productos\n",
    "top_10_productos = retail_clean.groupby('Description')['TotalPrice'].sum().nlargest(10)\n",
    "producto_nombres_cortos = [p[:30] + '...' if len(p) > 30 else p for p in top_10_productos.index]\n",
    "axes[1].barh(range(len(top_10_productos)), top_10_productos.values, color='#FF6B6B')\n",
    "axes[1].set_yticks(range(len(top_10_productos)))\n",
    "axes[1].set_yticklabels(producto_nombres_cortos, fontsize=9)\n",
    "axes[1].set_title('Top 10 Productos por Ingresos', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Ingresos ($)')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final del an√°lisis\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMEN EJECUTIVO DEL AN√ÅLISIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n1. VOLUMEN DE NEGOCIO:\")\n",
    "print(f\"   - Transacciones analizadas: {len(retail_clean):,}\")\n",
    "print(f\"   - Ingresos totales: ${retail_clean['TotalPrice'].sum():,.2f}\")\n",
    "print(f\"   - Ticket promedio: ${retail_clean['TotalPrice'].mean():,.2f}\")\n",
    "print(f\"   - Clientes √∫nicos: {retail_clean['CustomerID'].nunique():,}\")\n",
    "\n",
    "print(f\"\\n2. PRODUCTOS:\")\n",
    "print(f\"   - Productos √∫nicos: {retail_clean['Description'].nunique()}\")\n",
    "print(f\"   - Producto m√°s vendido: {top_productos_cantidad.index[0]}\")\n",
    "print(f\"   - Producto m√°s rentable: {top_productos_ingresos.index[0]}\")\n",
    "\n",
    "print(f\"\\n3. GEOGRAF√çA:\")\n",
    "print(f\"   - Principal mercado: {ventas_pais.index[0]} ({ventas_pais.iloc[0]['Ingresos_Totales'] / ventas_pais['Ingresos_Totales'].sum() * 100:.1f}%)\")\n",
    "print(f\"   - Pa√≠ses activos: {len(ventas_pais)}\")\n",
    "\n",
    "print(f\"\\n4. PATRONES TEMPORALES:\")\n",
    "print(f\"   - D√≠a de la semana con m√°s ventas: {ventas_dia_semana.index[0]}\")\n",
    "print(f\"   - Hora pico: {hora_pico}:00\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mineria-datos-itam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
